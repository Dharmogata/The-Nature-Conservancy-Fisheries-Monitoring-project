{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish image classification with Keras Continued\n",
    " \n",
    " Let's digging deeper into Keras!\n",
    " \n",
    " note :This notebook is inspired by Traffic_Signs_Recognition project in SelfDrivingCarND\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "starting by Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data(data_dir):\n",
    "    # Get all subdirectories of data_dir. Each represents a label.\n",
    "    directories = [d for d in os.listdir(data_dir)\n",
    "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    # Loop through the label directories and collect the data in\n",
    "    # two lists, labels and images.\n",
    "    labels = []\n",
    "    images = []\n",
    "\n",
    "    category = 0\n",
    "    for d in directories:\n",
    "        label_dir = os.path.join(data_dir, d)\n",
    "        file_names = [os.path.join(label_dir, f)\n",
    "                      for f in os.listdir(label_dir)\n",
    "                      if f.endswith(\".jpg\")]\n",
    "        \n",
    "       \n",
    "        for f in file_names:\n",
    "            img = cv2.imread(f)\n",
    "            imresize = cv2.resize(img, (200, 125))\n",
    "            #plt.imshow(imresize)\n",
    "            images.append(imresize)\n",
    "            labels.append(category)\n",
    "        category += 1\n",
    "        \n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join('/home/suh/바탕화면/train')\n",
    "images, labels = load_train_data(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (32, 32), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "def load_test_data():\n",
    "    import glob\n",
    "    path = os.path.join( '/home/suh/바탕화면/test_stg1/*.jpg')\n",
    "    files = sorted(glob.glob(path))\n",
    "\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(flbase)\n",
    "\n",
    "    return test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_images,test_labels = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = images, labels\n",
    "X_test, y_test = test_images, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training example: 3777\n",
      "Number of testing examples: 1000 \n",
      "Image data shape: (125, 200, 3)\n",
      "Number of classes: 8\n"
     ]
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training example: {}\".format(n_train))\n",
    "print(\"Number of testing examples: {} \".format(n_test))\n",
    "print(\"Image data shape: {}\".format(image_shape)) \n",
    "print(\"Number of classes: {}\".format(n_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validate the Network\n",
    "Split the training data into a training and validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.15, random_state=432422)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 200, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3210, 125, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train).astype('float32')\n",
    "X_val =np.array(X_val).astype('float32')\n",
    "X_train = X_train / 255 - 0.5\n",
    "X_val = X_val / 255 - 0.5\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Two-Layer Feedfoward Network\n",
    "The code which is written so far is for data processing, not specific to Keras. thus, let's build Keras-specific code. Build a two-layer feedforward neural network, with 128 neurons in the fully-connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_train.shape[1:] == (125,200,3)), \"The dimensions of the images are not 125 x 200x 3.\"\n",
    "#assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_val.shape[1:] == (125,200,3)), \"The dimensions of the images are not 125 x 200 x 3.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "assert(math.isclose(np.min(X_train), -0.5, abs_tol=1e-5) and math.isclose(np.max(X_train), 0.5, abs_tol=1e-5)), \"The range of the training data is: %.1f to %.1f\" % (np.min(X_train), np.max(X_train))\n",
    "assert(math.isclose(np.min(X_val), -0.5, abs_tol=1e-5) and math.isclose(np.max(X_val), 0.5, abs_tol=1e-5)), \"The range of the validation data is: %.1f to %.1f\" % (np.min(X_val), np.max(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a two-layer feedforward neural network with Keras here.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(125*200*3,)))\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7fd4e32011b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3210\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "dense_layers = []\n",
    "for l in model.layers:\n",
    "    if type(l) == Dense:\n",
    "        dense_layers.append(l)\n",
    "assert(len(dense_layers) == 2), \"There should be 2 Dense layers.\"\n",
    "d1 = dense_layers[0]\n",
    "d2 = dense_layers[1]\n",
    "assert(d1.input_shape == (None, 3210))\n",
    "assert(d1.output_shape == (None, 128))\n",
    "assert(d2.input_shape == (None, 128))\n",
    "assert(d2.output_shape == (None, 43))\n",
    "\n",
    "last_layer = model.layers[-1]\n",
    "assert(last_layer.activation.__name__ == 'softmax'), \"Last layer should be softmax activation, is {}.\".format(last_layer.activation.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 (None, 75000) (None, 128) <function relu at 0x7f0f0e784510>\n",
      "dense_2 (None, 128) (None, 43) <function softmax at 0x7f0f0e7842f0>\n"
     ]
    }
   ],
   "source": [
    "# Debugging\n",
    "for l in model.layers:\n",
    "    print(l.name, l.input_shape, l.output_shape, l.activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "Compile and train the network for 2 epochs. Use the adam optimizer, with categorical_crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 128)           9600128     dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 43)            5547        dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9605675\n",
      "____________________________________________________________________________________________________\n",
      "Train on 3210 samples, validate on 567 samples\n",
      "Epoch 1/20\n",
      "3210/3210 [==============================] - 15s - loss: 7.1135 - acc: 0.5087 - val_loss: 7.0650 - val_acc: 0.5414\n",
      "Epoch 2/20\n",
      "3210/3210 [==============================] - 13s - loss: 6.9117 - acc: 0.5592 - val_loss: 6.7719 - val_acc: 0.5697\n",
      "Epoch 3/20\n",
      "3210/3210 [==============================] - 13s - loss: 6.5961 - acc: 0.5757 - val_loss: 6.9512 - val_acc: 0.5397\n",
      "Epoch 4/20\n",
      "3210/3210 [==============================] - 14s - loss: 6.1222 - acc: 0.6069 - val_loss: 5.9097 - val_acc: 0.6279\n",
      "Epoch 5/20\n",
      "3210/3210 [==============================] - 13s - loss: 5.7258 - acc: 0.6336 - val_loss: 6.2760 - val_acc: 0.5996\n",
      "Epoch 6/20\n",
      "3210/3210 [==============================] - 14s - loss: 5.6511 - acc: 0.6274 - val_loss: 5.1354 - val_acc: 0.6437\n",
      "Epoch 7/20\n",
      "3210/3210 [==============================] - 15s - loss: 5.1355 - acc: 0.6558 - val_loss: 5.3777 - val_acc: 0.6279\n",
      "Epoch 8/20\n",
      "3210/3210 [==============================] - 13s - loss: 4.7984 - acc: 0.6798 - val_loss: 4.6830 - val_acc: 0.6896\n",
      "Epoch 9/20\n",
      "3210/3210 [==============================] - 13s - loss: 4.4226 - acc: 0.7093 - val_loss: 4.5532 - val_acc: 0.6808\n",
      "Epoch 10/20\n",
      "3210/3210 [==============================] - 14s - loss: 4.3065 - acc: 0.7184 - val_loss: 4.3576 - val_acc: 0.7090\n",
      "Epoch 11/20\n",
      "3210/3210 [==============================] - 13s - loss: 4.2811 - acc: 0.7196 - val_loss: 5.1967 - val_acc: 0.6437\n",
      "Epoch 12/20\n",
      "3210/3210 [==============================] - 13s - loss: 4.7024 - acc: 0.6931 - val_loss: 4.4909 - val_acc: 0.7072\n",
      "Epoch 13/20\n",
      "3210/3210 [==============================] - 13s - loss: 4.1452 - acc: 0.7321 - val_loss: 4.4282 - val_acc: 0.7160\n",
      "Epoch 14/20\n",
      "3210/3210 [==============================] - 13s - loss: 4.1017 - acc: 0.7405 - val_loss: 4.3463 - val_acc: 0.7143\n",
      "Epoch 15/20\n",
      "3210/3210 [==============================] - 13s - loss: 3.9330 - acc: 0.7414 - val_loss: 4.6243 - val_acc: 0.6772\n",
      "Epoch 16/20\n",
      "3210/3210 [==============================] - 13s - loss: 3.8106 - acc: 0.7520 - val_loss: 4.2426 - val_acc: 0.7249\n",
      "Epoch 17/20\n",
      "3210/3210 [==============================] - 13s - loss: 3.7254 - acc: 0.7645 - val_loss: 4.2040 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "3210/3210 [==============================] - 14s - loss: 3.7459 - acc: 0.7567 - val_loss: 4.2161 - val_acc: 0.7196\n",
      "Epoch 19/20\n",
      "3210/3210 [==============================] - 15s - loss: 3.7167 - acc: 0.7636 - val_loss: 4.1736 - val_acc: 0.7160\n",
      "Epoch 20/20\n",
      "3210/3210 [==============================] - 13s - loss: 3.6784 - acc: 0.7685 - val_loss: 4.1861 - val_acc: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile and train the model here.\n",
    "from keras.utils import np_utils\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 43)\n",
    "Y_val = np_utils.to_categorical(y_val, 43)\n",
    "\n",
    "X_train= X_train.reshape(-1, 125*200*3)\n",
    "X_val = X_val.reshape(-1, 125*200*3)\n",
    "\n",
    "model.summary()\n",
    "# TODO: Compile and train the model here.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=128, nb_epoch=20,\n",
    "                    verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is: 0.732\n"
     ]
    }
   ],
   "source": [
    "print( \"The validation accuracy is: %.3f\" % history.history['val_acc'][-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Convolutions\n",
    "Build a new network, similar to your existing network. Before the hidden layer, add a 3x3 convolutional layer with 32 filters and valid padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 200, 3)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 123, 198, 32)  896         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 123, 198, 32)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 779328)        0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           99754112    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 8)             1032        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 99756040\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "# TODO: Re-construct the network and add a convolutional layer before the first fully-connected layer.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=432422)\n",
    "\n",
    "# TODO: Implement data normalization here.\n",
    "def normalize_img(image):\n",
    "    return cv2.normalize(image, None, alpha=-0.5, beta=0.5, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "X_train = np.array([normalize_img(image) for image in X_train], dtype=np.float32)\n",
    "X_val = np.array([normalize_img(image) for image in X_val], dtype=np.float32)\n",
    "\n",
    "print(X_train.shape[1:])\n",
    "layer1_depth = 32\n",
    "filter_size = 3\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_neurons = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(layer1_depth, filter_size, filter_size, border_mode='valid', input_shape = (125, 200, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_neurons))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3210 samples, validate on 567 samples\n",
      "Epoch 1/2\n",
      "3210/3210 [==============================] - 1105s - loss: 8.8076 - acc: 0.4480 - val_loss: 8.2438 - val_acc: 0.4885\n",
      "Epoch 2/2\n",
      "3210/3210 [==============================] - 981s - loss: 8.8775 - acc: 0.4492 - val_loss: 8.2438 - val_acc: 0.4885\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile and train the model here.\n",
    "y_train = np.array(y_train).astype(int)\n",
    "y_val = np.array(y_val).astype(int)\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes=num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, nb_classes=num_classes)\n",
    "\n",
    "X_train = X_train.reshape(-1, 125, 200, 3)\n",
    "X_val = X_val.reshape(-1,125, 200, 3)\n",
    "\n",
    "nb_epoch = 2\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is: 0.489\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( \"The validation accuracy is: %.3f\" % history.history['val_acc'][-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "Re-construct your network and add a 2x2 pooling layer immediately following your convolutional layer.\n",
    "Then compile and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_2 (Convolution2D)  (None, 121, 196, 32)  2432        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 121, 196, 32)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 60, 98, 32)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 188160)        0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           24084608    flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2)             258         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2)             0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 24087298\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Re-construct the network and add a convolutional layer before the first fully-connected layer.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=432422)\n",
    "\n",
    "# TODO: Implement data normalization here.\n",
    "def normalize_img(image):\n",
    "    return cv2.normalize(image, None, alpha=-0.5, beta=0.5, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "X_train = np.array([normalize_img(image) for image in X_train], dtype=np.float32)\n",
    "X_val = np.array([normalize_img(image) for image in X_val], dtype=np.float32)\n",
    "\n",
    "layer1_depth = 32\n",
    "filter_size = 5\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_neurons = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(layer1_depth, filter_size, filter_size, border_mode='valid', input_shape = (125, 200, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_neurons))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2728 samples, validate on 482 samples\n",
      "Epoch 1/2\n",
      "2728/2728 [==============================] - 201s - loss: 8.3754 - acc: 0.4644 - val_loss: 8.4369 - val_acc: 0.4419\n",
      "Epoch 2/2\n",
      "2728/2728 [==============================] - 212s - loss: 2.9668 - acc: 0.6404 - val_loss: 0.6779 - val_acc: 0.7925\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile and train the model here.\n",
    "y_train = np.array(y_train).astype(int)\n",
    "y_val = np.array(y_val).astype(int)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes=num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, nb_classes=num_classes)\n",
    "\n",
    "X_train = X_train.reshape(-1, 125, 200, 3)\n",
    "X_val = X_val.reshape(-1, 125, 200, 3)\n",
    "\n",
    "nb_epoch = 2\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is: 0.793\n"
     ]
    }
   ],
   "source": [
    "print( \"The validation accuracy is: %.3f\" % history.history['val_acc'][-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "Re-construct your network and add dropout after the pooling layer. Set the dropout rate to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 121, 196, 32)  2432        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 121, 196, 32)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 60, 98, 32)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 60, 98, 32)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 188160)        0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           24084608    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 128)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 8)             1032        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 24088072\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Re-construct the network and add a convolutional layer before the first fully-connected layer.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=432422)\n",
    "\n",
    "# TODO: Implement data normalization here.\n",
    "def normalize_img(image):\n",
    "    return cv2.normalize(image, None, alpha=-0.5, beta=0.5, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "X_train = np.array([normalize_img(image) for image in X_train], dtype=np.float32)\n",
    "X_val = np.array([normalize_img(image) for image in X_val], dtype=np.float32)\n",
    "\n",
    "layer1_depth = 32\n",
    "filter_size = 5\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_neurons = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(layer1_depth, filter_size, filter_size, border_mode='valid', input_shape = (125, 200, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_neurons))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2318 samples, validate on 410 samples\n",
      "Epoch 1/2\n",
      "2318/2318 [==============================] - 177s - loss: 8.7081 - acc: 0.4435 - val_loss: 8.4129 - val_acc: 0.4780\n",
      "Epoch 2/2\n",
      "2318/2318 [==============================] - 172s - loss: 8.8378 - acc: 0.4517 - val_loss: 8.4129 - val_acc: 0.4780\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile and train the model here.\n",
    "\n",
    "y_train = np.array(y_train).astype(int)\n",
    "y_val = np.array(y_val).astype(int)\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes=num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, nb_classes=num_classes)\n",
    "\n",
    "X_train = X_train.reshape(-1, 125, 200, 3)\n",
    "X_val = X_val.reshape(-1, 125, 200, 3)\n",
    "\n",
    "nb_epoch = 2\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is: 0.478\n"
     ]
    }
   ],
   "source": [
    "print( \"The validation accuracy is: %.3f\" % history.history['val_acc'][-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Once picked out the best model, it's time to test it.\n",
    "Load up the test data and use the evaluate() method to see how well it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'img_00005.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c3556a34974b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'img_00005.jpg'"
     ]
    }
   ],
   "source": [
    "def normalize_img(image):\n",
    "    return cv2.normalize(image, None, alpha=-0.5, beta=0.5, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "X_test = np.array([normalize_img(image) for image in X_test], dtype=np.float32)\n",
    "y_test =  np.array(y_test).astype(int)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes=num_classes)\n",
    "\n",
    "X_test = X_test.reshape(-1, 125, 200, 3)\n",
    "\n",
    "# TODO: Evaluate model on test data\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
